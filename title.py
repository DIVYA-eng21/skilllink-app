# -*- coding: utf-8 -*-
"""title.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TwOpAbfFpAEMMHIB96Qodk6TfOjN0xgr
"""

pip install transformers datasets sentencepiece accelerate torch

from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Trainer, TrainingArguments
from datasets import Dataset
import pandas as pd

dataset=pd.read_csv('skill_title_dataset.csv')

from google.colab import files

uploaded = files.upload()

for fn in uploaded.keys():
  print('User uploaded file "{name}" with length {length} bytes'.format(
      name=fn, length=len(uploaded[fn])))

from sklearn.model_selection import train_test_split
train_df, test_df = train_test_split(dataset, test_size=0.1, random_state=42)

train_dataset = Dataset.from_pandas(train_df)
test_dataset = Dataset.from_pandas(test_df)

model_name = "google/flan-t5-base"

tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

def preprocess_function(examples):
    inputs = []
    for desc in examples["Description"]:
        # Instruction-style input to handle multilingual text
        prompt = f"Translate to English and convert skill description into a short English job title: {desc}"
        inputs.append(prompt)
    targets = examples["Title"]
    model_inputs = tokenizer(inputs, max_length=128, truncation=True,padding="max_length")
    labels = tokenizer(targets, max_length=32, truncation=True,padding="max_length")
    model_inputs["labels"] = labels["input_ids"]
    return model_inputs

tokenized_train = train_dataset.map(preprocess_function, batched=True)
tokenized_test = test_dataset.map(preprocess_function, batched=True)



# def preprocess_function(examples):
#     inputs = [f"Generate a short job title for: {desc}" for desc in examples["description"]]
#     model_inputs = tokenizer(inputs, max_length=64, truncation=True, padding="max_length")
#     labels = tokenizer(text_target=examples["title"], max_length=16, truncation=True, padding="max_length")
#     model_inputs["labels"] = labels["input_ids"]
#     return model_inputs

# tokenized_dataset = dataset.map(preprocess_function, batched=True)

training_args = TrainingArguments(
    output_dir="./flan-skilltitle-model",
    #evaluation_strategy="epoch",
    learning_rate=3e-4,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    num_train_epochs=5,
    weight_decay=0.01,
    save_total_limit=1,
    logging_steps=100,
    push_to_hub=False,
    report_to="none"
)

# Step 7: Trainer setup
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_train,
    eval_dataset=tokenized_test,
    tokenizer=tokenizer
)

trainer.train()

!ls /content/flan-skilltitle-model

trainer.save_model("./flan-skilltitle-model")
tokenizer.save_pretrained("./flan-skilltitle-model")

!ls -lh

from google.colab import files
!zip -r flan-skilltitle-model.zip flan-skilltitle-model
files.download("flan-skilltitle-model.zip")



from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

tokenizer = AutoTokenizer.from_pretrained("./flan-skilltitle-model")
model = AutoModelForSeq2SeqLM.from_pretrained("./flan-skilltitle-model")

# def generate_title(description):
#     input_text = f"Convert this person's work description into a short English job title Description: {description}"
#     inputs = tokenizer(input_text, return_tensors="pt")
#     outputs = model.generate(**inputs, max_length=32, num_beams=5)
#     return tokenizer.decode(outputs[0], skip_special_tokens=True)

# print(generate_title("मैं खाना बनाता हूं और ग्राहकों को परोसता हूं"))

# print(generate_title("मैं खाना बनाता हूं और ग्राहकों को परोसता हूं"))  # Expected: Cook or Waiter
# print(generate_title("Yo reparo muebles rotos y hago sillas de madera"))  # Expected: Carpenter
# print(generate_title("I design embroidery on sarees"))  # Expected: Embroidery Designer

from huggingface_hub import login
login()

from huggingface_hub import HfApi

api = HfApi()
api.upload_folder(
    folder_path="./flan-skilltitle-model",  # Your trained model folder
    repo_id="Divya21026/flan-skilltitle-model",  # Choose repo name
    repo_type="model"
)